{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **IMPORTING LIBRARIES**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all required libraries\n",
    "import numpy as np ## for linear algebra\n",
    "import pandas as pd ## data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt ## for visualisation\n",
    "%matplotlib inline\n",
    "import seaborn as sns ## for visualisation\n",
    "import warnings ## for filterout warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **LOADING THE DATA**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "sales_train = pd.read_csv('train.csv',parse_dates=['date'] ,index_col=['date'])\n",
    "sales_test = pd.read_csv('test.csv',parse_dates=['date'] ,index_col=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df=sales_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **EXAMINING THE DATA**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_train = sales_train.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the first couple of rows in the data\n",
    "sales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train info (data types and number of rows)\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values for train and test\n",
    "sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many stores and items are there?\n",
    "sales['store'].nunique(), sales_test['store'].nunique(),sales['item'].nunique(), sales_test['item'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **EXPLORATORY DATA ANALYSIS**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales_train.loc[sales_train['store']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales=sales_train.loc[sales_train['item']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot showing the sales data trend, we can see that the sales ahve been trending upwords for the past 5 years with highs and lows at the mid year and beginning of year mark.\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(sales.sales.resample('w').sum(),label=\"sales\")\n",
    "plt.title(\"Store 1 Item Sales for 2015-2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calcualte the 10 day moving average to smooth out the data points - 21.28 \n",
    "sales['sales'].mean = sales['sales'].rolling(window=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_train['sales'].mean.plot()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(sales['sales'].mean.resample('W').sum(),label=\"sales\")\n",
    "plt.title(\"Store 1 Item MA10 Sales for 2015-2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset for every shop and visualize sales trend\n",
    "\n",
    "shop1 = sales_train[sales_train.store==1]['sales'].sort_index(ascending=True)\n",
    "shop2 = sales_train[sales_train.store==2]['sales'].sort_index(ascending=True)\n",
    "shop3 = sales_train[sales_train.store==3]['sales'].sort_index(ascending=True)\n",
    "shop4 = sales_train[sales_train.store==4]['sales'].sort_index(ascending=True)\n",
    "shop5 = sales_train[sales_train.store==5]['sales'].sort_index(ascending=True)\n",
    "shop6 = sales_train[sales_train.store==6]['sales'].sort_index(ascending=True)\n",
    "shop7 = sales_train[sales_train.store==7]['sales'].sort_index(ascending=True)\n",
    "shop8 = sales_train[sales_train.store==8]['sales'].sort_index(ascending=True)\n",
    "shop9 = sales_train[sales_train.store==9]['sales'].sort_index(ascending=True)\n",
    "shop10 = sales_train[sales_train.store==10]['sales'].sort_index(ascending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig,(ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10) = plt.subplots(10,figsize=(20,70))\n",
    "shop1.resample('w').sum().plot(ax=ax1,title='Store 1 Sales')\n",
    "shop2.resample('w').sum().plot(ax=ax2,title='Store 2 Sales')\n",
    "shop3.resample('w').sum().plot(ax=ax3,title='Store 3 Sales')\n",
    "shop4.resample('w').sum().plot(ax=ax4,title='Store 4 Sales')\n",
    "shop5.resample('w').sum().plot(ax=ax5,title='Store 5 Sales')\n",
    "shop6.resample('w').sum().plot(ax=ax6,title='Store 6 Sales')\n",
    "shop7.resample('w').sum().plot(ax=ax7,title='Store 7 Sales')\n",
    "shop8.resample('w').sum().plot(ax=ax8,title='Store 8 Sales')\n",
    "shop9.resample('w').sum().plot(ax=ax9,title='Store 9 Sales')\n",
    "shop10.resample('w').sum().plot(ax=ax10,title='Store 10 Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the Quantile-Quantile Plot (QQ Plot), used to determine whether a data set is distributed a certain way and usually showcases how the data fits a normal distribution\n",
    "import scipy.stats\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.probplot(sales.sales, plot = pylab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QQ plot takes all the values a variable can take, and arranges them in accending order, the y-axis expresses the price with the highest being at the top and lowest at the bottom. \n",
    "The x-axis represents how many standard deviations away from the mean these values are. The red diagonal line represents what the data points shoudl follow if they are noramlly distributed. \n",
    "In our case our data is not noramlly distributed since there are more values around the zero mark then we should, there for our data is not normally distributed and we cannot use normal distribution to make forcasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sales['item'], sales['store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### **WHITE NOISE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = np.random.normal(loc=sales_train_df.sales.mean(), scale = sales_train_df.sales.std(), size = len(sales_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_df['wn'] = wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(sales_train_df.wn.resample('w').sum(),label=\"sales\")\n",
    "plt.title(\"White Noise Time-Series\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(sales_train_df.sales.resample('w').sum(),label=\"sales\")\n",
    "plt.ylim(50000,300000)\n",
    "plt.title(\"Sales 2015-2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "\n",
    "### **STATIONARITY OR NON-STATIONARITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "dftest = adfuller(sales['sales'], autolag = 'AIC')\n",
    "print(\"1. ADF: \", dftest[0])\n",
    "print(\"2. P-value: \", dftest[1])\n",
    "print(\"3. Num of Lags: \", dftest[2])\n",
    "print(\"4. Num of Oberservations Used for ADF Regression and Critical Values Calculations: \", dftest[3])\n",
    "print(\"5. Critical Values:\")\n",
    "for key , val in dftest[4].items():\n",
    "    print(\"\\t\", key, \": \", val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### **SEASONALITY**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sales['sales'].resample('w').mean() \n",
    "\n",
    "result = sm.tsa.seasonal_decompose(y, model='additive')\n",
    "fig = plt.figure()  \n",
    "fig = result.plot()  \n",
    "fig.set_size_inches(20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = sales['sales'].resample('w').mean() \n",
    "\n",
    "result = sm.tsa.seasonal_decompose(z, model='multiplicative')\n",
    "fig = plt.figure()  \n",
    "fig = result.plot()  \n",
    "fig.set_size_inches(20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ACF**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code below takes 5 mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "pacf=plot_pacf(sales['sales'], lags=25)\n",
    "acf=plot_acf(sales['sales'], lags=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sales.iloc[0:14608] ## train \n",
    "test = sales.iloc[14608:] ## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima # --> pip install this\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_fit = auto_arima(sales['sales'], trace=True, suppress_warnings=True)\n",
    "stepwise_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sales.shape)\n",
    "#train=sales.iloc[:1461]\n",
    "#test=sales.iloc[1461:]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ARIMA(train['sales'],order=(5,1,2))\n",
    "model=model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=len(train)\n",
    "end=len(train)+len(test)-1\n",
    "pred=model.predict(start=start,end=end,typ='levels')\n",
    "print(pred)\n",
    "pred.index=sales.index[start:end+1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.plot(legend=True)\n",
    "test['sales'].plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = sqrt(mean_squared_error(pred, test['sales']))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=ARIMA(sales['sales'], order=(5,1,2))\n",
    "model2=model2.fit()\n",
    "sales.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_future_dates=pd.date_range(start='2017-12-31', end='2018-01-31')\n",
    "print(index_future_dates)\n",
    "pred=model2.predict(start=len(sales),end=len(sales)+31,typ='levels').rename('ARIMA Predictions')\n",
    "#print(comp_pred)\n",
    "pred.index=index_future_dates\n",
    "print(pred.index)\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anvil Uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yyyy-mm-dd: 2018-12-31\n",
      "yyyy-mm-dd: 2019-01-31\n"
     ]
    }
   ],
   "source": [
    "a=input('yyyy-mm-dd: ')\n",
    "b=input('yyyy-mm-dd: ')\n",
    "\n",
    "#2018-12-31\n",
    "#2019-01-31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2018-12-31', '2019-01-01', '2019-01-02', '2019-01-03',\n",
      "               '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07',\n",
      "               '2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11',\n",
      "               '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15',\n",
      "               '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19',\n",
      "               '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23',\n",
      "               '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27',\n",
      "               '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "2018-12-31    20.009661\n",
      "2019-01-01    18.943766\n",
      "2019-01-02    17.814788\n",
      "2019-01-03    18.797962\n",
      "2019-01-04    20.404586\n",
      "2019-01-05    21.718020\n",
      "2019-01-06    21.660654\n",
      "2019-01-07    21.074279\n",
      "2019-01-08    20.351041\n",
      "2019-01-09    19.964455\n",
      "Freq: D, Name: ARIMA Predictions, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_date_range = pd.date_range(start=a,end=b)\n",
    "pred.index = user_date_range\n",
    "print(pred.index)\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.predict(start=a,end=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import anvil.server\n",
    "\n",
    "anvil.server.connect(\"KWZLDYZCM63NAOSZZLL3NEQC-K4TPWXJQR3RK3YTD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil\n",
    "@anvil.server.callable\n",
    "def sale_prediction(a,b):\n",
    "    \n",
    "    d_range = pd.date_range(start = a, end = b)\n",
    "    pred.index = d_range\n",
    "    return pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anvil\n",
    "@anvil.server.callable\n",
    "def sale_prediction(d_range):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
